{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce74938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cc44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b138d77",
   "metadata": {},
   "source": [
    "# Create Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbfef8",
   "metadata": {},
   "source": [
    "### Processing and Encoding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df.set_index('PassengerId', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d919c3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>113803</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>7.25</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>7.925</td>\n",
       "      <td>53.1</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C123</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0  \\\n",
       "PassengerId                        1   \n",
       "Survived                           0   \n",
       "Pclass                             3   \n",
       "Name         Braund, Mr. Owen Harris   \n",
       "Sex                             male   \n",
       "Age                             22.0   \n",
       "SibSp                              1   \n",
       "Parch                              0   \n",
       "Ticket                     A/5 21171   \n",
       "Fare                            7.25   \n",
       "Cabin                            NaN   \n",
       "Embarked                           S   \n",
       "\n",
       "                                                             1  \\\n",
       "PassengerId                                                  2   \n",
       "Survived                                                     1   \n",
       "Pclass                                                       1   \n",
       "Name         Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "Sex                                                     female   \n",
       "Age                                                       38.0   \n",
       "SibSp                                                        1   \n",
       "Parch                                                        0   \n",
       "Ticket                                                PC 17599   \n",
       "Fare                                                   71.2833   \n",
       "Cabin                                                      C85   \n",
       "Embarked                                                     C   \n",
       "\n",
       "                                  2  \\\n",
       "PassengerId                       3   \n",
       "Survived                          1   \n",
       "Pclass                            3   \n",
       "Name         Heikkinen, Miss. Laina   \n",
       "Sex                          female   \n",
       "Age                            26.0   \n",
       "SibSp                             0   \n",
       "Parch                             0   \n",
       "Ticket             STON/O2. 3101282   \n",
       "Fare                          7.925   \n",
       "Cabin                           NaN   \n",
       "Embarked                          S   \n",
       "\n",
       "                                                        3  \\\n",
       "PassengerId                                             4   \n",
       "Survived                                                1   \n",
       "Pclass                                                  1   \n",
       "Name         Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "Sex                                                female   \n",
       "Age                                                  35.0   \n",
       "SibSp                                                   1   \n",
       "Parch                                                   0   \n",
       "Ticket                                             113803   \n",
       "Fare                                                 53.1   \n",
       "Cabin                                                C123   \n",
       "Embarked                                                S   \n",
       "\n",
       "                                    4  \n",
       "PassengerId                         5  \n",
       "Survived                            0  \n",
       "Pclass                              3  \n",
       "Name         Allen, Mr. William Henry  \n",
       "Sex                              male  \n",
       "Age                              35.0  \n",
       "SibSp                               0  \n",
       "Parch                               0  \n",
       "Ticket                         373450  \n",
       "Fare                             8.05  \n",
       "Cabin                             NaN  \n",
       "Embarked                            S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe598185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3183a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.PassengerId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834c387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88c5b5",
   "metadata": {},
   "source": [
    "Cleaning Pipeline:\n",
    "- Remove unnecessary columns\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21875df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']\n",
    "reduced_df = df.drop(drop_features, axis=1)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8436ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "numeric_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e719c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "categorical_transfomer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c5a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preporcessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "         (\"drop\",'drop',drop_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db1d4401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53037664, -0.50244517,  0.43279337, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.57183099,  0.78684529,  0.43279337, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.25482473, -0.48885426, -0.4745452 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [        nan, -0.17626324,  0.43279337, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.25482473, -0.04438104, -0.4745452 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15850313, -0.49237783, -0.4745452 , ...,  1.        ,\n",
       "         0.        ,  0.        ]], shape=(891, 13))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preporcessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b77f7b",
   "metadata": {},
   "source": [
    "# Trining Pipelien\n",
    "### processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import joblib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from feature_engine.imputation import MeanMedianImputer\n",
    "# from feature_engine.encoding import OneHotEncoder\n",
    "# from feature_engine.selection import DropFeatures\n",
    "# from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SOURCE = os.path.join(\"data\", \"raw\")\n",
    "# DESTINATION = os.path.join(\"data\", \"processed\")\n",
    "\n",
    "# def dtype_conversion(X, cat_cols):\n",
    "#     \"\"\"Handle missing values and convert to categorical\"\"\"\n",
    "#     X = X.copy()\n",
    "#     for col in cat_cols:\n",
    "#         if col in X.columns:\n",
    "#             # Fill NA and convert to category\n",
    "#             X[col] = X[col].fillna('missing').astype('category')\n",
    "#     return X\n",
    "# def read_process_data(\n",
    "#     file_name: str,\n",
    "#     target: str,\n",
    "#     num_cols: list,\n",
    "#     cat_cols: list,\n",
    "#     drop_cols: list,\n",
    "#     logger\n",
    "# ):\n",
    "#     \"\"\"Data processing pipeline\"\"\"\n",
    "#     logger.info(\"Starting data processing\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. Load data\n",
    "#         df = pd.read_csv(os.path.join(SOURCE, f'{file_name}.csv'))\n",
    "#         logger.info(f\"Raw data loaded: {df.shape}\")\n",
    "        \n",
    "#         # 2. Validate initial data\n",
    "#         if df[target].isna().any():\n",
    "#             raise ValueError(f\"Target column '{target}' contains missing values\")\n",
    "        \n",
    "#         # 3. Split data\n",
    "#         train_df, test_df = train_test_split(\n",
    "#             df, test_size=0.2, random_state=42, stratify=df[target]\n",
    "#         )\n",
    "#         logger.info(f\"Train/Test split: {train_df.shape}/{test_df.shape}\")\n",
    "\n",
    "#         # 4. Create processing pipeline\n",
    "#         processing_pipeline = Pipeline([\n",
    "#             ('dtype_conversion', FunctionTransformer(\n",
    "#                 func=dtype_conversion,\n",
    "#                 kw_args={'cat_cols': cat_cols},\n",
    "#                 validate=False\n",
    "#             )),\n",
    "            \n",
    "#             ('numeric_imputer', MeanMedianImputer(\n",
    "#                 imputation_method='median',\n",
    "#                 variables=num_cols\n",
    "#             )),\n",
    "            \n",
    "#             ('encoder', OneHotEncoder(\n",
    "#                 drop_last=True,\n",
    "#                 variables=cat_cols\n",
    "#             )),\n",
    "            \n",
    "#             ('scaler', SklearnTransformerWrapper(\n",
    "#                 transformer=StandardScaler(),\n",
    "#                 variables=num_cols\n",
    "#             )),\n",
    "            \n",
    "#             ('drop_features', DropFeatures(\n",
    "#                 features_to_drop=drop_cols + [target]\n",
    "#             ))\n",
    "#         ])\n",
    "\n",
    "#         # 5. Process data\n",
    "#         X_train = processing_pipeline.fit_transform(train_df)\n",
    "#         X_test = processing_pipeline.transform(test_df)\n",
    "\n",
    "#         # 6. Combine with target (critical fix)\n",
    "#         train_clean = pd.concat([\n",
    "#             X_train,\n",
    "#             train_df[target].rename(target)  # Preserve original index\n",
    "#         ], axis=1)\n",
    "        \n",
    "#         test_clean = pd.concat([\n",
    "#             X_test,\n",
    "#             test_df[target].rename(target)  # Preserve original index\n",
    "#         ], axis=1)\n",
    "\n",
    "#         # 7. Validate output\n",
    "#         if len(train_clean) != len(train_df):\n",
    "#             raise ValueError(\"Row count mismatch in training data\")\n",
    "#         if len(test_clean) != len(test_df):\n",
    "#             raise ValueError(\"Row count mismatch in test data\")\n",
    "\n",
    "#         # 8. Save artifacts\n",
    "#         os.makedirs(DESTINATION, exist_ok=True)\n",
    "#         train_clean.to_parquet(os.path.join(DESTINATION, f\"{file_name}-train.parquet\"))\n",
    "#         test_clean.to_parquet(os.path.join(DESTINATION, f\"{file_name}-test.parquet\"))\n",
    "#         joblib.dump(processing_pipeline, os.path.join(DESTINATION, \"pipeline.pkl\"))\n",
    "\n",
    "#         logger.info(f\"Processing complete. Final shapes: Train {train_clean.shape}, Test {test_clean.shape}\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Processing failed: {str(e)}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf5812",
   "metadata": {},
   "source": [
    "### Training and Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import pickle\n",
    "# SOURCE = os.path.join(\"data\", \"processed\")\n",
    "# MODEL_PATH = 'models'\n",
    "# def encode_target(file_name : str, \n",
    "#                   target_col : str,\n",
    "#                   model_name : str,\n",
    "#                   logger):\n",
    "#     df_train = pd.read_parquet(os.path.join(DESTINATION, f\"{file_name}-train.parquet\"))\n",
    "#     df_test = pd.read_parquet(os.path.join(DESTINATION, f\"{file_name}-test.parquet\"))\n",
    "#     X_train , y_train = df_train.drop(columns=[target_col],axis=1) , df_train[target_col]    \n",
    "#     X_test ,y_test = df_test.drop(columns=[target_col],axis=1) , df_test[target_col]\n",
    "\n",
    "#     logger.info(\"Fitting the encoder/decoder of target variable\")\n",
    "#     logger.info(f\"Number of classes: {len(y_train.unique())}\")\n",
    "#     \"\"\"Create and fit encoder/decoder for target variable\"\"\"\n",
    "#     encoder = LabelEncoder()\n",
    "#     encoder.fit(y_train)\n",
    "#     # Create decoder mapping\n",
    "#     classes = encoder.classes_\n",
    "#     decoder = {i: cls for i, cls in enumerate(classes)}\n",
    "#     target_translator = {\n",
    "#         'encoder': encoder,\n",
    "#         'decoder': decoder,\n",
    "#     }\n",
    "#     logger.info(\"encoder/decoder of target created successfully\")\n",
    "#     # Save the artifacts\n",
    "    \n",
    "#     if not os.path.exists(os.path.join(MODEL_PATH, model_name)):\n",
    "#         os.makedirs(os.path.join(MODEL_PATH, model_name))\n",
    "#     with open(\n",
    "#         os.path.join(MODEL_PATH, model_name, \"model_target_translator.pkl\"),\n",
    "#         \"wb\",\n",
    "#     ) as pkl:\n",
    "#         pickle.dump(target_translator, pkl)\n",
    "#     logger.info(\"encoder/decoder of target saved\")\n",
    "#     return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13dd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# import os\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "# from hyperopt.pyll import scope\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# N_FOLDS = 3\n",
    "# MAX_EVALS = 3\n",
    "\n",
    "# # Updated search space with compatible parameters\n",
    "# SPACE = {\n",
    "#     \"penalty\": hp.choice(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
    "#     \"C\": hp.loguniform(\"C\", -4, 4),\n",
    "#     \"solver\": hp.choice(\"solver\", [\"saga\"]),  # Saga supports all penalties\n",
    "#     \"l1_ratio\": hp.uniform(\"l1_ratio\", 0, 1)  # Required for elasticnet\n",
    "# }\n",
    "\n",
    "# def objective(params, X, y, n_folds: int = N_FOLDS):\n",
    "#     \"\"\"Wrapper function for hyperparameter optimization\"\"\"\n",
    "#     try:\n",
    "#         # Handle elasticnet specific parameters\n",
    "#         if params[\"penalty\"] == \"elasticnet\":\n",
    "#             params[\"l1_ratio\"] = params.get(\"l1_ratio\", 0.5)\n",
    "#         else:\n",
    "#             params.pop(\"l1_ratio\", None)\n",
    "            \n",
    "#         model = LogisticRegression(**params, max_iter=1000)\n",
    "#         scores = cross_validate(\n",
    "#             model, X, y, \n",
    "#             cv=n_folds, \n",
    "#             scoring=\"accuracy\",\n",
    "#             error_score=\"raise\"  # Get detailed errors\n",
    "#         )\n",
    "#         return {\n",
    "#             \"loss\": -np.mean(scores[\"test_score\"]),  # Minimize negative accuracy\n",
    "#             \"params\": params,\n",
    "#             \"status\": STATUS_OK\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         return {\n",
    "#             \"loss\": 0,\n",
    "#             \"status\": STATUS_FAIL,\n",
    "#             \"exception\": str(e)\n",
    "#         }\n",
    "\n",
    "# def train_model(X, y, model_name: str, logger):\n",
    "#     \"\"\"Complete training pipeline with error handling\"\"\"\n",
    "#     logger.info(\"Loading target encoder/decoder\")\n",
    "#     try:\n",
    "#         with open(os.path.join(MODEL_PATH, model_name, \"model_target_translator.pkl\"), \"rb\") as pkl:\n",
    "#             translator = pickle.load(pkl)\n",
    "        \n",
    "#         y_train_enc = translator['encoder'].transform(y)\n",
    "        \n",
    "#         logger.info(\"Starting hyperparameter optimization\")\n",
    "#         bayes_trials = Trials()\n",
    "        \n",
    "#         best = fmin(\n",
    "#             fn=partial(objective, X=X, y=y_train_enc),\n",
    "#             space=SPACE,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=MAX_EVALS,\n",
    "#             trials=bayes_trials,\n",
    "#             show_progressbar=False\n",
    "#         )\n",
    "        \n",
    "#         # Get best parameters from trials\n",
    "#         best_params = bayes_trials.best_trial[\"result\"][\"params\"]\n",
    "#         logger.info(f\"Best parameters: {best_params}\")\n",
    "        \n",
    "#         # Train final model\n",
    "#         final_model = LogisticRegression(**best_params, max_iter=1000)\n",
    "#         final_model.fit(X, y_train_enc)\n",
    "        \n",
    "#         # Save artifacts\n",
    "#         os.makedirs(os.path.join(MODEL_PATH, model_name), exist_ok=True)\n",
    "#         with open(os.path.join(MODEL_PATH, model_name, \"final_model.pkl\"), \"wb\") as pkl:\n",
    "#             pickle.dump(final_model, pkl)\n",
    "            \n",
    "#         logger.info(\"Model trained and saved successfully\")\n",
    "        \n",
    "        \n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Training failed: {str(e)}\")\n",
    "#         raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466cb72",
   "metadata": {},
   "source": [
    "### Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b19272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import pickle\n",
    "# from sklearn.metrics import classification_report\n",
    "# from skore import EstimatorReport\n",
    "\n",
    "# MODEL_PATH = \"models\"\n",
    "# REPORT_PATH = \"reports\"\n",
    "# def evaluate(X_test, y_test, model_name: str, logger):\n",
    "#     \"\"\"Proper evaluation function with correct encoding\"\"\"\n",
    "#     logger.info(\"Starting model evaluation\")\n",
    "    \n",
    "#     try:\n",
    "#         # Load artifacts\n",
    "#         with open(os.path.join(MODEL_PATH, model_name, \"model_target_translator.pkl\"), \"rb\") as pkl:\n",
    "#             translator = pickle.load(pkl)\n",
    "            \n",
    "#         with open(os.path.join(MODEL_PATH, model_name, \"final_model.pkl\"), \"rb\") as pkl:\n",
    "#             model = pickle.load(pkl)\n",
    "        \n",
    "#         # Encode test labels\n",
    "#         y_test_enc = translator['encoder'].transform(y_test)\n",
    "        \n",
    "#         # Generate predictions\n",
    "#         y_pred = model.predict(X_test)\n",
    "        \n",
    "#         # Convert numeric class labels to strings\n",
    "#         class_names = [str(v) for v in translator['decoder'].values()]\n",
    "        \n",
    "#         # Generate classification report\n",
    "#         evaluation_report = classification_report(\n",
    "#             y_test_enc,\n",
    "#             y_pred,\n",
    "#             target_names=class_names  # Use string labels\n",
    "#         )\n",
    "        \n",
    "#         logger.info(\"saving evaluation report\")\n",
    "#         if not os.path.exists(os.path.join(REPORT_PATH, model_name)):\n",
    "#             os.makedirs(os.path.join(REPORT_PATH, model_name))\n",
    "#         with open(\n",
    "#             os.path.join(REPORT_PATH, model_name, \"evaluation_report.json\"), \"w\"\n",
    "#         ) as js:\n",
    "#             json.dump(evaluation_report, js, indent=4)\n",
    "#         logger.info(f\"Evaluation Report:\\n{evaluation_report}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Evaluation failed: {str(e)}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac1617",
   "metadata": {},
   "source": [
    "### Trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b0d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logger import ExecutorLogger\n",
    "from src.training.process_data import read_process_data\n",
    "from src.training.evaluate import evaluate\n",
    "from src.training.train import train_model,encode_target\n",
    "\n",
    "logger = ExecutorLogger('train pipeline')\n",
    "def train_pipeline(logger: ExecutorLogger):\n",
    "    # process pipeline\n",
    "    numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "    categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "    drop_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']\n",
    "    logger.info(\"Training Started...\")\n",
    "    read_process_data(\n",
    "        file_name ='titanic',\n",
    "        target = 'Survived',\n",
    "        num_cols = numeric_features,\n",
    "        cat_cols= categorical_features,\n",
    "        drop_cols = drop_features,\n",
    "        logger = logger\n",
    "    )\n",
    "    X_train, y_train, X_test, y_test = encode_target(file_name ='titanic', \n",
    "                  target_col = 'Survived',\n",
    "                  model_name = 'basemodel',\n",
    "                  logger = logger)\n",
    "    train_model(X = X_train,\n",
    "            y = y_train,\n",
    "            model_name = 'basemodel',\n",
    "            logger = logger)\n",
    "    evaluate(X_test, y_test, \"basemodel\", logger)\n",
    "    logger.info(\"Training Completed...\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be3ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 14:01:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTraining Started...\u001b[0m\n",
      "\u001b[32m2025-05-01 14:01:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mStarting data processing\u001b[0m\n",
      "\u001b[32m2025-05-01 14:01:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mRaw data loaded: (891, 12)\u001b[0m\n",
      "\u001b[32m2025-05-01 14:01:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTrain/Test split: (712, 12)/(179, 12)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 14:02:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mProcessing complete. Final shapes: Train (712, 11), Test (179, 11)\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFitting the encoder/decoder of target variable\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mNumber of classes: 2\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mencoder/decoder of target created successfully\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mencoder/decoder of target saved\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLoading target encoder/decoder\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mStarting hyperparameter optimization\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mBest parameters: {'C': 0.04803799418099026, 'penalty': 'l2', 'solver': 'saga'}\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mModel trained and saved successfully\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mStarting model evaluation\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1msaving evaluation report\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mEvaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       110\n",
      "           1       0.86      0.61      0.71        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.82      0.77      0.79       179\n",
      "weighted avg       0.82      0.81      0.80       179\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-01 14:02:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTraining Completed...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_pipeline(logger = ExecutorLogger('training logger'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
